{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "import geocoder\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Importiamo tqdm per la barra di avanzamento\n",
    "from math import radians, sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all dataframes with the addresses\n",
    "\n",
    "directory_path = '/Users/dilettaferri/Desktop/UNIPI/SNA - Project/Project/dataframe con indirizzi'\n",
    "# Reads all .csv files in the directory\n",
    "dataframes = [pd.read_csv(os.path.join(directory_path, file)) for file in os.listdir(directory_path) if file.endswith('.csv')] \n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True) # Unites all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the \"None\"\n",
    "conteggio_none = df.isna().sum()\n",
    "conteggio_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the records of the dataframe that have one or more \"None\" in the geographic columns added\n",
    "colonne_geografiche_aggiunte = ['stato', 'provincia', 'comune', 'indirizzo']\n",
    "df_senza_na = df.dropna(subset=colonne_geografiche_aggiunte)\n",
    "\n",
    "df_senza_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count again the number of records with each different type of organization\n",
    "df_senza_na.value_counts('Sezione')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the single record with \"-\" in the Sezione column (it would be a node without label)\n",
    "riga_no_sezione = df[df['Sezione'] == '-'].index\n",
    "df_senza_na.drop(riga_no_sezione, inplace=True)\n",
    "\n",
    "df_senza_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "df_senza_na.value_counts('Sezione')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = copy.deepcopy(df_senza_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the records where province and municipality are not the same as the original ones\n",
    "# These records will be eliminated (we have no way of easily knowing which is the correct one)\n",
    "\n",
    "righe_da_eliminare = df1[(df1['Provincia'] != df1['provincia']) | (df1['Comune'] != df1['comune'])]\n",
    "df1.drop(righe_da_eliminare.index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the useless or duplicated columns\n",
    "df1.drop(columns=['Provincia', 'Comune', 'Regione', 'Repertorio', 'Codice fiscale', 'Data iscrizione', 'Rete', '5x1000'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an abbreviation for the different names in the \"Sezione\" columns - useful as labels for the network \n",
    "mappatura = {\n",
    "    'ASSOCIAZIONI DI PROMOZIONE SOCIALE': 'APS',\n",
    "    'ORGANIZZAZIONI DI VOLONTARIATO': 'OV',\n",
    "    'IMPRESE SOCIALI': 'IS',\n",
    "    'ALTRI ENTI DEL TERZO SETTORE': 'AE',\n",
    "    'ENTI FILANTROPICI': 'EF',\n",
    "    \"SOCIETA' DI MUTUO SOCCORSO\": 'SMS'\n",
    "}\n",
    "\n",
    "# Create the new \"etichetta\" column from the mapping\n",
    "df1['etichetta'] = df1['Sezione'].map(mappatura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add latitude and longitude from the addresses</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the completed address\n",
    "df1['indirizzo_completo'] = df1['indirizzo'] + ',' + df1['comune'] + ',' + df1['provincia'] + ',' + df1['stato']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = []\n",
    "long = []\n",
    "\n",
    "for i in df1['indirizzo_completo']:\n",
    "    g = geocoder.arcgis(i)\n",
    "    coordinate = g.latlng\n",
    "    lat.append(coordinate[0])\n",
    "    long.append(coordinate[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Latitudine'] = lat\n",
    "df1['Longitudine'] = long\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the whole dataframe with lat and long\n",
    "df1.to_csv('dataframe_coordinate.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualization with Folium map</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean of the lat and long in order to center the map\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa_lombardia = folium.Map(location=(45.532592, 9.474202), zoom_start=9)\n",
    "#mappa_lombardia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add points as clusters\n",
    "datapoints = plugins.MarkerCluster().add_to(mappa_lombardia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the dataframe and add each data point to the mark cluster\n",
    "for lat, lng, label, in zip(df1.Latitudine, df1.Longitudine, df1.Denominazione): # Use as label the name of the org\n",
    "    folium.Marker(\n",
    "        location=[lat, lng],\n",
    "        icon=None,\n",
    "        popup=label,\n",
    "    ).add_to(datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappa_lombardia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's possible to see from the Folium map visualization that there are some points outside of the boundaries of the Lombardia region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload GeoJSON file with boundaries of Lombardia \n",
    "geojson_path = \"Limiti amministrativi Regione Lombardia 2019 con aggiornamenti DbT_PGT.geojson\"  \n",
    "folium.GeoJson(\n",
    "    geojson_path,  # Aggiungi GeoJSON file to the map \n",
    "    name='Confini Lombardia',\n",
    "    style_function=lambda x: {'color': 'blue', 'weight': 2, 'fillOpacity': 0.1} \n",
    ").add_to(mappa_lombardia)\n",
    "\n",
    "# Control layer to activate/deactivate the border \n",
    "folium.LayerControl().add_to(mappa_lombardia)\n",
    "\n",
    "# Save the map in a .html in order to visualize it\n",
    "mappa_lombardia.save(\"mappa_lombardia_con_confini.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll create a nwe column which tells if a point (identified by lat, long is inside or outside the border of Lombardia). <br>\n",
    "These points will be dropped, because they will create wrong distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the GeoJSON of the border \n",
    "geojson_path = \"Limiti amministrativi Regione Lombardia 2019 con aggiornamenti DbT_PGT.geojson\"\n",
    "lombardia_gdf = gpd.read_file(geojson_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"Point\" geometry for each record of the DataFrame\n",
    "df1['geometry'] = df1.apply(lambda row: Point(row['Longitudine'], row['Latitudine']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df1 in a GeoDataFrame in order to work with the geometries\n",
    "df1_gdf = gpd.GeoDataFrame(df1, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if every point is inside the border, and save the answer in the column inside_lombardia\n",
    "df1_gdf['inside_lombardia'] = df1_gdf['geometry'].apply(lambda x: lombardia_gdf.contains(x).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_gdf = df1_gdf[df1_gdf['inside_lombardia'] == True]\n",
    "df2_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df2 as a traditional dataframe\n",
    "df2 = df2_gdf.drop(columns='geometry') \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize again the map to check if all the points are within the borders\n",
    "\n",
    "# Create map centered in Lombardia\n",
    "mappa_lombardia2 = folium.Map(location=(45.532592, 9.474202), zoom_start=9)\n",
    "\n",
    "datapoints2 = plugins.MarkerCluster().add_to(mappa_lombardia2)\n",
    "\n",
    "# Add points from df2\n",
    "for lat, lng, label, in zip(df2.Latitudine, df2.Longitudine, df2.Denominazione): #uso come label il nome dell'ente\n",
    "    folium.Marker(\n",
    "        location=[lat, lng],\n",
    "        icon=None,\n",
    "        popup=label,\n",
    "    ).add_to(datapoints2)\n",
    "\n",
    "# Add borders\n",
    "folium.GeoJson(\n",
    "    lombardia_gdf.geometry,\n",
    "    name=\"Confini Lombardia\",\n",
    "    style_function=lambda x: {'color': 'blue', 'weight': 2, 'fillOpacity': 0.1}\n",
    ").add_to(mappa_lombardia2)\n",
    "\n",
    "\n",
    "# Add control layer\n",
    "folium.LayerControl().add_to(mappa_lombardia2)\n",
    "\n",
    "# Visualize map\n",
    "#mappa_lombardia\n",
    "\n",
    "# Save\n",
    "mappa_lombardia2.save(\"mappa_lombardia_con_confini_2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates in the \"Denominazione\" columns\n",
    "df2_no_duplicates = df2.drop_duplicates(subset=['Denominazione'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_no_duplicates.reset_index(drop=True, inplace=True)\n",
    "df2_no_duplicates\n",
    "\n",
    "# Final dataset has 16828 records (from the original 17687)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='/Users/dilettaferri/Desktop/UNIPI/SNA - Project/Project/df_finale_coordinate.csv'\n",
    "\n",
    "#salvo il csv\n",
    "df2_no_duplicates.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Distances</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finale =pd.read_csv('df_finale_coordinate.csv')\n",
    "df_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the Haversine distance vectorized with NumPy\n",
    "def haversine_vectorized(lat1, lon1, lat2, lon2):\n",
    "    # Earth radius in km \n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert coordinates from degrees to radiants \n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    # Distance in km\n",
    "    distance = R * c\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NumPy array for latitudes and longitudes\n",
    "lat = df_finale['Latitudine'].values\n",
    "lon = df_finale['Longitudine'].values\n",
    "n = len(df_finale)\n",
    "\n",
    "# Create an empty matrix for the distances \n",
    "distanze = np.zeros((n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances between each pair of org \n",
    "for i in tqdm(range(n), desc=\"Calcolo distanze\"):\n",
    "    # Get i-th record coordinates\n",
    "    coords_1_lat = lat[i]\n",
    "    coords_1_lon = lon[i]\n",
    "\n",
    "    distanze[i, i+1:] = haversine_vectorized(coords_1_lat, coords_1_lon, lat[i+1:], lon[i+1:])\n",
    "    distanze[i+1:, i] = distanze[i, i+1:]  # Riempire la parte simmetrica della matrice\n",
    "\n",
    "# Convert NumPy matrix in a Pandas dataframe \n",
    "df_distanze = pd.DataFrame(distanze, index=df_finale['Denominazione'], columns=df_finale['Denominazione'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distanze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save .csv\n",
    "file_path='/Users/dilettaferri/Desktop/UNIPI/SNA - Project/Project/df_distanze.csv'\n",
    "\n",
    "df_distanze.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
